{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set autoreload to reload all external modules automatically (otherwise changes to those modules won't take effect in the notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from make_folder_dataset import MakeFolderDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load environment variables from .env file in repo root\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "#DATASET_REPO_ROOT_PATH=<absolute-path-to-dataset-repo-root-folder>\n",
    "dataset_repo_root_path = Path(os.environ.get(\"DATASET_REPO_ROOT_PATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set True / False to enable / disable data set persisting\n",
    "save_dataset = True\n",
    "specific_instances = None\n",
    "specific_plot_target = [] # plots everything if None, nothing if [], specific targets if [<list-of-targets>]\n",
    "x_y_data_suffix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset instances\n",
    "# use current git repo root folder as a reliable \"base\" folder. Dataset folders should be under <git-root>\\dataset\\\n",
    "instances: list[MakeFolderDataset] = []\n",
    "raw_data_path = dataset_repo_root_path / \"rawData\"\n",
    "for p in raw_data_path.iterdir():\n",
    "    if specific_instances is not None and p.name not in specific_instances:\n",
    "        continue\n",
    "    if p.is_dir() and not p.name == \"_ignore\":\n",
    "        instance = MakeFolderDataset(p.absolute())\n",
    "        instance.extract_robot_data()\n",
    "        instance.get_labels_all()\n",
    "        instances.append(instance)\n",
    "\n",
    "print(f\"found {len(instances)} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add contact labels from true_label dataframe to robot-data dataframe for all instances\n",
    "for inst in instances:\n",
    "    inst.df = pd.merge_asof(left=inst.df, right=inst.true_label[[\"time\", \"DATA0\"]], on=\"time\", tolerance=0.02)\n",
    "    inst.df.rename(columns={\"DATA0\": \"has_contact\"}, inplace=True)\n",
    "    inst.df[\"has_contact\"] = inst.df[\"has_contact\"].fillna(0)\n",
    "\n",
    "    if inst.df.loc[1, 'has_contact'] == 1:\n",
    "        inst.df.loc[0, 'has_contact'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up faulty (true_label) sensor data\n",
    "# IMPORTANT: assume that the first measurement (time-window with has_contact = 1) is correct and can be used as a reference point to clean the remaining instance\n",
    "# thus it must manually be verified that the first measurement of each instance is indeed correct\n",
    "\n",
    "def get_contact_duration(df, time):\n",
    "    start_time_index = df[(df['time'] < time) & (\n",
    "        df['has_contact'] == 0)].index[-1] + 1\n",
    "    start_time = df.loc[start_time_index, 'time']\n",
    "    try:\n",
    "        end_time_index = df[(inst.df['time'] > time) & (\n",
    "            df['has_contact'] == 0)].index[0] - 1\n",
    "    except IndexError:\n",
    "        # occurs if filtered df above is empty, which means there is no row with has_contact = 0 after specified time\n",
    "        end_time_index = df.index[-1]\n",
    "    end_time = df.loc[end_time_index, 'time']\n",
    "    return (end_time - start_time), start_time, end_time\n",
    "\n",
    "\n",
    "def get_next_contact_time(df, excl_from_time):\n",
    "    # time of contact time-window must always be greater than time of 1st no-contact\n",
    "    # -> exclude any cut-off contact time-windows at start of measurement\n",
    "    first_no_contact_time = df[df['has_contact'] == 0].iloc[0]['time']\n",
    "    filtered_df = df[(df['time'] > first_no_contact_time) & (\n",
    "        df['time'] > excl_from_time) & (df['has_contact'] == 1)]\n",
    "    return (filtered_df.iloc[0]['time'], filtered_df.index[0]) if len(filtered_df) > 0 else (None, None)\n",
    "\n",
    "\n",
    "for inst in instances:\n",
    "    inst.df['has_contact_original'] = inst.df.loc[:, 'has_contact']\n",
    "\n",
    "    # calculate duration of 1st contact time-window\n",
    "    # 1st contact time-window starts at 1st row with has_contact = 1, where a previous row with has_contact = 0 exists\n",
    "    contact_time, _ = get_next_contact_time(inst.df, inst.start_from_time)\n",
    "    reference_duration, reference_start_time, reference_end_time = get_contact_duration(\n",
    "        inst.df, contact_time)\n",
    "\n",
    "    # set has_contact to 0 for all rows before 1st actuall contact time-window\n",
    "    inst.df.loc[inst.df[\"time\"] < contact_time, \"has_contact\"] = 0\n",
    "\n",
    "    # inst.first_contact_start_time = reference_start_time\n",
    "    # inst.window_size = window_size = len(inst.df[(inst.df['time'] >= reference_start_time) & (\n",
    "    #    inst.df['time'] <= reference_end_time)])\n",
    "\n",
    "    # set has_contact to 0 for all contact time-windows with duration outside of [<lower-bound-multiplier>*reference_duration, <upper-bound-multiplier>*reference_duration]\n",
    "    # -> remove faulty time-windows\n",
    "    # multiplier values can be set manually in meta.json, defaults are 0.85 and 1.2\n",
    "    last_contact_end_time = reference_end_time\n",
    "    reference_duration_multiplier_lower = inst.reference_duration_multiplier_lower if inst.reference_duration_multiplier_lower is not None else 0.85\n",
    "    reference_duration_multiplier_upper = inst.reference_duration_multiplier_upper if inst.reference_duration_multiplier_upper is not None else 1.2\n",
    "    while True:\n",
    "        contact_time, _ = get_next_contact_time(inst.df, last_contact_end_time)\n",
    "        if contact_time is None:\n",
    "            break\n",
    "        contact_duration, contact_start_time, contact_end_time = get_contact_duration(\n",
    "            inst.df, contact_time)\n",
    "        if not (reference_duration_multiplier_lower * reference_duration <= contact_duration <= reference_duration_multiplier_upper * reference_duration):\n",
    "            # print(contact_duration, contact_start_time, contact_end_time)\n",
    "            inst.df.loc[(inst.df['time'] >= contact_start_time) & (\n",
    "                inst.df['time'] <= contact_end_time), 'has_contact'] = 0\n",
    "        last_contact_end_time = contact_end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_position = ['e0','e1','e2','e3','e4','e5','e6']\n",
    "target_velocity = ['de0','de1','de2','de3','de4','de5','de6']\n",
    "target_torques = ['etau_J0','etau_J1', 'etau_J2', 'etau_J3', 'etau_J4', 'etau_J5', 'etau_J6']\n",
    "target = target_torques + target_position + target_velocity\n",
    "\n",
    "plot_target = target if specific_plot_target is None else specific_plot_target\n",
    "for i in plot_target:\n",
    "    for inst in instances:\n",
    "        # label gets scaled otherwise measure and label are not visible properly on plot\n",
    "        A = inst.df[i].max()-inst.df[i].min()\n",
    "        inst.df['has_contact_scaled'] = inst.df['has_contact'] * \\\n",
    "            A + inst.df[i].min()\n",
    "        inst.df['has_contact_original_scaled'] = inst.df['has_contact_original'] * \\\n",
    "            A + inst.df[i].min()\n",
    "        # use plotly to make interactive plots\n",
    "        trace_has_contact = go.Scatter(\n",
    "            x=inst.df['time'], y=inst.df['has_contact_scaled'], name='has contact')\n",
    "        trace_has_contact_original = go.Scatter(\n",
    "            x=inst.df['time'], y=inst.df['has_contact_original_scaled'], name='has contact original')\n",
    "        trace_robotdata = go.Scatter(\n",
    "            x=inst.df['time'], y=inst.df[i], mode='lines', name='robot data')\n",
    "        data = [trace_has_contact_original, trace_robotdata, trace_has_contact]\n",
    "        layout = go.Layout(title=f'{i} (instance {os.path.basename(os.path.normpath(inst.path))})',\n",
    "                           xaxis=dict(title='time(sec)'),\n",
    "                           yaxis=dict(title='Y-axis'))\n",
    "        fig = go.Figure(data=data, layout=layout)\n",
    "        iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(X, y, X_filename, y_filename):\n",
    "    processed_data_path = dataset_repo_root_path / \"processedData\"\n",
    "    X_path = processed_data_path / X_filename\n",
    "    y_path = processed_data_path / y_filename\n",
    "    print(\n",
    "        f\"saving dataset as: {str(X_path.absolute())} / {str(y_path.absolute())}\")\n",
    "    np.save(str(X_path.absolute()), X)\n",
    "    np.save(str(y_path.absolute()), y)\n",
    "\n",
    "\n",
    "X_single_on_contact, y_single_on_contact = [], []\n",
    "X_single_left_offset, y_single_left_offset = [], []\n",
    "X_sliding_left_offset, y_sliding_left_offset = [], []\n",
    "\n",
    "# 40 data points with robot data publish frequency of 200Hz -> 200ms time-windows\n",
    "window_size = 40\n",
    "# -20 data points offset on the left of a time window with freq. of 200Hz -> include data up to 100ms before contact for sliding windows\n",
    "window_left_offset = -20\n",
    "\n",
    "for inst in instances:\n",
    "    contact_end_time = -1\n",
    "    while True:\n",
    "        contact_time, contact_time_index = get_next_contact_time(inst.df, contact_end_time)\n",
    "        if contact_time is None:\n",
    "            break\n",
    "\n",
    "        _, _, contact_end_time = get_contact_duration(inst.df, contact_time)\n",
    "\n",
    "        # append contact time-windows to feature matrices\n",
    "        # append to feature matrix where time-windows start exactly at time of contact, with fixed window size\n",
    "        X_single_on_contact.append(\n",
    "            inst.df.iloc[contact_time_index:contact_time_index+window_size][target].to_numpy())\n",
    "        y_single_on_contact.append(inst.contact_type)\n",
    "\n",
    "        if contact_time_index + window_left_offset >= 0:\n",
    "            # append to feature matrix where time-windows start left (by defined offset) of time of contact, with fixed window size\n",
    "            X_single_left_offset.append(\n",
    "                inst.df.iloc[contact_time_index+window_left_offset:contact_time_index+window_left_offset+window_size][target].to_numpy())\n",
    "            y_single_left_offset.append(inst.contact_type)\n",
    "\n",
    "            # append to sliding window feature matrix: start left (by offset) of time of contact, fixed window size\n",
    "            # move sliding window to the right by 4 rows (= 20ms) each step and append until end of contact time-window is reached by right side of sliding window,\n",
    "            # or until offset equals 20 (-> 100ms after initial contact) to avoid including data too late after initial contact\n",
    "            window_current_offset = window_left_offset\n",
    "            while inst.df.iloc[contact_time_index+window_current_offset+window_size]['time'] <= contact_end_time and window_current_offset <= 20:\n",
    "                X_sliding_left_offset.append(\n",
    "                    inst.df.iloc[contact_time_index+window_current_offset:contact_time_index+window_current_offset+window_size][target].to_numpy())\n",
    "                y_sliding_left_offset.append(inst.contact_type)\n",
    "                window_current_offset += 4\n",
    "\n",
    "X_single_on_contact = np.array(X_single_on_contact)\n",
    "print(\"shape of single on contact feature / label matrices: \")\n",
    "print(np.shape(X_single_on_contact))\n",
    "print(np.shape(y_single_on_contact))\n",
    "print()\n",
    "\n",
    "X_single_left_offset = np.array(X_single_left_offset)\n",
    "print(\"shape of single left offset from contact feature / label matrices: \")\n",
    "print(np.shape(X_single_left_offset))\n",
    "print(np.shape(y_single_left_offset))\n",
    "print()\n",
    "\n",
    "X_sliding_left_offset = np.array(X_sliding_left_offset)\n",
    "print(\"shape of sliding window w/ left offset from contact feature / label matrices: \")\n",
    "print(np.shape(X_sliding_left_offset))\n",
    "print(np.shape(y_sliding_left_offset))\n",
    "print()\n",
    "\n",
    "if save_dataset:\n",
    "    save_data(X_single_on_contact, y_single_on_contact, f\"x_single_on_contact{x_y_data_suffix}.npy\", f\"y_single_on_contact{x_y_data_suffix}.npy\")\n",
    "    save_data(X_single_left_offset, y_single_left_offset, f\"x_single_left_offset{x_y_data_suffix}.npy\", f\"y_single_left_offset{x_y_data_suffix}.npy\")\n",
    "    save_data(X_sliding_left_offset, y_sliding_left_offset, f\"x_sliding_left_offset{x_y_data_suffix}.npy\", f\"y_sliding_left_offset{x_y_data_suffix}.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
