{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "import numpy as np\n",
    "\n",
    "from make_folder_dataset import MakeFolderDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#load environment variables from .env file in repo root\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "#DATASET_REPO_ROOT_PATH=<absolute-path-to-dataset-repo-root-folder>\n",
    "dataset_repo_root_path = Path(os.environ.get(\"DATASET_REPO_ROOT_PATH\"))\n",
    "test_data_path = dataset_repo_root_path / \"testData\"\n",
    "\n",
    "labels_map = {'hard':0,'pvc_tube':1, 'soft':2}\n",
    "\n",
    "evaluation_period_after_contact_sec = 0.2\n",
    "evaluation_predictions_after_contact = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_contact_time(df, excl_from_time):\n",
    "    first_no_contact_time = df[df['has_contact'] == 0].iloc[0]['time']\n",
    "    filtered_df = df[(df['time'] > first_no_contact_time) & (\n",
    "        df['time'] > excl_from_time) & (df['has_contact'] == 1)]\n",
    "    return (filtered_df.iloc[0]['time'], filtered_df.index[0]) if len(filtered_df) > 0 else (None, None)\n",
    "\n",
    "def get_contact_duration(df, time):\n",
    "    start_time_index = df[(df['time'] < time) & (\n",
    "        df['has_contact'] == 0)].index[-1] + 1\n",
    "    start_time = df.loc[start_time_index, 'time']\n",
    "    try:\n",
    "        end_time_index = df[(df['time'] > time) & (\n",
    "            df['has_contact'] == 0)].index[0] - 1\n",
    "    except IndexError:\n",
    "        # occurs if filtered df above is empty, which means there is no row with has_contact = 0 after specified time\n",
    "        end_time_index = df.index[-1]\n",
    "    end_time = df.loc[end_time_index, 'time']\n",
    "    return (end_time - start_time), start_time, end_time\n",
    "\n",
    "def evaluation(path, inst: MakeFolderDataset):\n",
    "    time_after_contact_indices = np.array([])\n",
    "    nof_predictions_after_contact_indices = np.array([])\n",
    "    last_contact_end_time = -1\n",
    "    while True:\n",
    "        contact_time, contact_index = get_next_contact_time(inst.model_results, last_contact_end_time)\n",
    "        if contact_time is None:\n",
    "            break\n",
    "        _, _, last_contact_end_time = get_contact_duration(\n",
    "            inst.model_results, contact_time)        \n",
    "        next_indices = np.array((inst.model_results[(inst.model_results['time'] >= contact_time) & (inst.model_results['time'] <= contact_time + evaluation_period_after_contact_sec)].index.values))\n",
    "        time_after_contact_indices = np.concatenate((time_after_contact_indices, next_indices))\n",
    "        nof_predictions_after_contact_indices = np.concatenate((nof_predictions_after_contact_indices, np.arange(contact_index, contact_index + evaluation_predictions_after_contact)))\n",
    "\n",
    "    filtered_model_results_time = inst.model_results.iloc[time_after_contact_indices]\n",
    "    value_counts_time = filtered_model_results_time['contact_class_prediction'].value_counts()\n",
    "\n",
    "    filtered_model_results_nof_predictions = inst.model_results.iloc[nof_predictions_after_contact_indices]\n",
    "    value_counts_nof_predictions = filtered_model_results_nof_predictions['contact_class_prediction'].value_counts()\n",
    "\n",
    "\n",
    "    true_label = labels_map[inst.contact_type]\n",
    "    num_true_time = 0\n",
    "    num_true_nof_predictions = 0\n",
    "    try:\n",
    "        num_true_time = value_counts_time[true_label]\n",
    "        num_true_nof_predictions = value_counts_nof_predictions[true_label]\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    num_predicted_time = sum(value_counts_time[value_counts_time.index != -1])\n",
    "    num_predicted_nof_predictions = sum(value_counts_nof_predictions[value_counts_nof_predictions.index != -1])\n",
    "\n",
    "    print(f\"instance: {path.name} (target class: {inst.contact_type})\\n\")\n",
    "\n",
    "    print(f\"evaluated model results up to {evaluation_period_after_contact_sec}sec after first contact time\")\n",
    "    print(\"correctly classified predictions: \", num_true_time)\n",
    "    print(\"total predictions:\", num_predicted_time)\n",
    "    print(\"accuracy: \", str((num_true_time/num_predicted_time)*100) + \"%\\n\")\n",
    "    \n",
    "    print(f\"evaluated first {evaluation_predictions_after_contact} predictions per contact\")\n",
    "    print(\"correctly classified predictions: \", num_true_nof_predictions)\n",
    "    print(\"total predictions:\", num_predicted_nof_predictions)\n",
    "    #print(\"accuracy: \", str((num_true_nof_predictions/num_predicted_nof_predictions)*100) + \"%\")\n",
    "\n",
    "    #i = 'etau_J1'\n",
    "    #A= inst.df[i].max()-inst.df[i].min()\n",
    "\n",
    "    #inst.true_label['label_scaled']=inst.true_label['DATA0'] * A + inst.df[i].min()\n",
    "    #trace_robotdata = go.Scatter(\n",
    "    #    x=inst.df['time'], y=inst.df[i], mode='lines', name='robot data')\n",
    "    trace1 = go.Scatter(x=inst.true_label['time'], y=inst.true_label['DATA0'], name='contact')\n",
    "    trace2 = go.Scatter(x=inst.model_results['time'], y=inst.model_results['correctly_classified'], name='prediction correctness')\n",
    "    trace3 = go.Scatter(x=inst.model_results['time'], y=inst.model_results['contact_class_prediction'], name='prediction',mode=\"markers\")\n",
    "    data = [trace1, trace3, trace2]\n",
    "    layout = go.Layout(title=f'(instance {path.name})',\n",
    "                    xaxis=dict(title='time(sec)'),\n",
    "                    yaxis=dict(title='Y-axis'))\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances: list[tuple[Path, MakeFolderDataset]] = []\n",
    "for p in test_data_path.iterdir():\n",
    "    if p.is_dir() and p.name != \"_ignore\":\n",
    "        instance = MakeFolderDataset(p.absolute())\n",
    "        instance.extract_robot_data()\n",
    "        instance.get_labels_all()\n",
    "\n",
    "        instance.model_results = pd.read_csv(str((p / \"model_result.csv\").absolute()))\n",
    "        instance.model_results['time'] = instance.model_results['Time_sec'] + instance.model_results['Time_nsec']- instance.init_time\n",
    "        instance.model_results = pd.merge_asof(left=instance.model_results, right=instance.true_label[[\"time\", \"DATA0\"]], on=\"time\", tolerance=0.02)\n",
    "        instance.model_results.rename(columns={\"DATA0\": \"has_contact\"}, inplace=True)\n",
    "        instance.model_results[\"has_contact\"] = instance.model_results[\"has_contact\"].fillna(0)\n",
    "        instance.model_results['correctly_classified'] = (instance.model_results['contact_class_prediction'] == labels_map[instance.contact_type]).astype(int)\n",
    "\n",
    "        instances.append((p, instance))\n",
    "\n",
    "instances = sorted(instances, key=lambda i: i[0].name)\n",
    "for inst in instances:\n",
    "    evaluation(inst[0], inst[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
