{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from _util.make_folder_dataset import MakeFolderDataset\n",
    "\n",
    "\n",
    "#load environment variables from .env file in repo root\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "#DATASET_REPO_ROOT_PATH=<absolute-path-to-dataset-repo-root-folder>\n",
    "dataset_repo_root_path = Path(os.environ.get(\"DATASET_REPO_ROOT_PATH\"))\n",
    "test_data_path = dataset_repo_root_path / \"testData\" / \"static_dynamic\"\n",
    "\n",
    "labels_map = {0: \"static\", 1: \"dynamic\" }\n",
    "\n",
    "evaluation_period_after_contact_sec = 0.3\n",
    "evaluation_predictions_after_contact = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_contact_time(df, excl_from_time):\n",
    "    first_no_contact_time = df[df['has_contact'] == 0].iloc[0]['time']\n",
    "    filtered_df = df[(df['time'] > first_no_contact_time) & (\n",
    "        df['time'] > excl_from_time) & (df['has_contact'] == 1)]\n",
    "    return (filtered_df.iloc[0]['time'], filtered_df.index[0]) if len(filtered_df) > 0 else (None, None)\n",
    "\n",
    "\n",
    "def get_contact_duration(df, time):\n",
    "    start_time_index = df[(df['time'] < time) & (\n",
    "        df['has_contact'] == 0)].index[-1] + 1\n",
    "    start_time = df.loc[start_time_index, 'time']\n",
    "    try:\n",
    "        end_time_index = df[(df['time'] > time) & (\n",
    "            df['has_contact'] == 0)].index[0] - 1\n",
    "    except IndexError:\n",
    "        # occurs if filtered df above is empty, which means there is no row with has_contact = 0 after specified time\n",
    "        end_time_index = df.index[-1]\n",
    "    end_time = df.loc[end_time_index, 'time']\n",
    "    return (end_time - start_time), start_time, end_time\n",
    "\n",
    "\n",
    "def evaluation(path, inst: MakeFolderDataset):\n",
    "    time_after_contact_indices = []\n",
    "    nof_predictions_after_contact_indices = []\n",
    "    last_contact_end_time = -1\n",
    "    while True:\n",
    "        contact_time, contact_index = get_next_contact_time(\n",
    "            inst.model_results, last_contact_end_time)\n",
    "        if contact_time is None:\n",
    "            break\n",
    "        _, _, last_contact_end_time = get_contact_duration(\n",
    "            inst.model_results, contact_time)\n",
    "        time_after_contact_indices += inst.model_results[(inst.model_results['time'] >= contact_time) & (\n",
    "            inst.model_results['time'] <= contact_time + evaluation_period_after_contact_sec) & (inst.model_results[\"contact_class_prediction\"] != -1)].index.tolist()\n",
    "        nof_predictions_after_contact_indices += inst.model_results[(inst.model_results['time'] >= contact_time) & (inst.model_results[\"contact_class_prediction\"] != -1)].head(\n",
    "            evaluation_predictions_after_contact).index.tolist()\n",
    "\n",
    "    filtered_model_results_time = inst.model_results.iloc[time_after_contact_indices]\n",
    "    value_counts_time = filtered_model_results_time['contact_class_prediction'].value_counts(\n",
    "    )\n",
    "\n",
    "    filtered_model_results_nof_predictions = inst.model_results.iloc[\n",
    "        nof_predictions_after_contact_indices]\n",
    "    value_counts_nof_predictions = filtered_model_results_nof_predictions['contact_class_prediction'].value_counts(\n",
    "    )\n",
    "\n",
    "    true_label = inst.dynamic\n",
    "    num_true_time = 0\n",
    "    num_true_nof_predictions = 0\n",
    "    try:\n",
    "        num_true_time = value_counts_time[true_label]\n",
    "        num_true_nof_predictions = value_counts_nof_predictions[true_label]\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    num_predicted_time = sum(value_counts_time[value_counts_time.index != -1])\n",
    "    num_predicted_nof_predictions = sum(\n",
    "        value_counts_nof_predictions[value_counts_nof_predictions.index != -1])\n",
    "\n",
    "    print(f\"instance: {path.name} (target class: {inst.contact_type})\\n\")\n",
    "\n",
    "    print(\n",
    "        f\"evaluated model results up to {evaluation_period_after_contact_sec}sec after first contact time, with classification result != -1 (prediction was actually made)\")\n",
    "    print(\"correctly classified predictions: \", num_true_time)\n",
    "    print(\"total predictions:\", num_predicted_time)\n",
    "    print(\"accuracy: \", f\"{str((num_true_time/num_predicted_time)*100)}%\" if num_predicted_time !=\n",
    "          0 else \"NO AVAILABLE PREDICTIONS\")\n",
    "    print()\n",
    "\n",
    "    print(\n",
    "        f\"evaluated first {evaluation_predictions_after_contact} predictions per contact, with classification result != -1 (prediction was actually made)\")\n",
    "    print(\"average correctly classified predictions: \", num_true_nof_predictions / num_predicted_nof_predictions)\n",
    "    print(\"accuracy: \", f\"{str((num_true_nof_predictions/num_predicted_nof_predictions)*100)}%\" if num_predicted_nof_predictions !=\n",
    "          0 else \"NO AVAILABLE PREDICTIONS\")\n",
    "\n",
    "    model_results_classification_made = inst.model_results[(\n",
    "        inst.model_results[\"contact_class_prediction\"] != -1) | (inst.model_results[\"has_contact\"] == 0)]\n",
    "\n",
    "    trace1 = go.Scatter(\n",
    "        x=inst.true_label['time'], y=inst.true_label['DATA0'], name='contact')\n",
    "    trace2 = go.Scatter(\n",
    "        x=model_results_classification_made['time'], y=model_results_classification_made['correctly_classified'], name='prediction correctness', line=dict(width=3))\n",
    "    trace3 = go.Scatter(\n",
    "        x=inst.model_results['time'], y=inst.model_results['contact_class_prediction'], name=f\"prediction<br>({str(labels_map)})\", mode=\"markers\", marker=dict(color=\"#aaaaaa\"))\n",
    "    data = [trace1, trace3, trace2]\n",
    "    layout = go.Layout(title=f'(instance {path.name})',\n",
    "                       xaxis=dict(title='time(sec)'),\n",
    "                       yaxis=dict(title='Y-axis'))\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances: list[tuple[Path, MakeFolderDataset]] = []\n",
    "for p in test_data_path.iterdir():\n",
    "    if p.is_dir() and p.name != \"_ignore\":\n",
    "        instance = MakeFolderDataset(p.absolute())\n",
    "        instance.extract_robot_data()\n",
    "        instance.get_labels_all()\n",
    "\n",
    "        instance.model_results = pd.read_csv(\n",
    "            str((p / \"model_result.csv\").absolute()))\n",
    "        instance.model_results['time'] = instance.model_results['Time_sec'] + \\\n",
    "            instance.model_results['Time_nsec'] - instance.init_time\n",
    "        instance.model_results = pd.merge_asof(left=instance.model_results, right=instance.true_label[[\n",
    "                                               \"time\", \"DATA0\"]], on=\"time\", tolerance=0.02)\n",
    "        instance.model_results.rename(\n",
    "            columns={\"DATA0\": \"has_contact\"}, inplace=True)\n",
    "        instance.model_results[\"has_contact\"] = instance.model_results[\"has_contact\"].fillna(\n",
    "            0)\n",
    "\n",
    "        cond1 = instance.model_results['has_contact'] == 1\n",
    "        cond2 = instance.model_results['contact_class_prediction'] == instance.dynamic\n",
    "        instance.model_results['correctly_classified'] = np.where(\n",
    "            cond1 & cond2, 1, 0)\n",
    "\n",
    "        instances.append((p, instance))\n",
    "\n",
    "instances = sorted(instances, key=lambda i: i[0].name)\n",
    "for inst in instances:\n",
    "    evaluation(inst[0], inst[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
